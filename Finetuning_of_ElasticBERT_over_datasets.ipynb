{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZrkmpkW8Wbj"
      },
      "source": [
        "# Part-1 : Section A\n",
        "Training a multi-exit ElasticBERT model on SST-2 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "dI-MguCnonl9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
        "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
        "# os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CkfzdLG9C1T",
        "outputId": "a7400ed9-42af-4197-ba5e-a1b1bb03fa34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/divya/divyaJyoti/UBERT/MutiExitDNNs/ElasticBERT\n",
            "Requirement already satisfied: transformers==4.6.1 in /home/divya/.local/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (4.6.1)\n",
            "Requirement already satisfied: fitlog in /home/divya/.local/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.9.15)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/divya/.local/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 1)) (2023.6.3)\n",
            "Requirement already satisfied: requests in /home/divya/.local/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: filelock in /home/divya/.local/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 1)) (3.12.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/divya/.local/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 1)) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /home/divya/.local/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 1)) (0.0.53)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /home/divya/.local/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 1)) (0.0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/divya/.local/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 1)) (4.65.0)\n",
            "Requirement already satisfied: packaging in /home/divya/.local/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/divya/.local/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /home/divya/.local/lib/python3.8/site-packages (from fitlog->-r requirements.txt (line 2)) (0.6.2)\n",
            "Requirement already satisfied: flask>=1.0.2 in /home/divya/.local/lib/python3.8/site-packages (from fitlog->-r requirements.txt (line 2)) (2.3.2)\n",
            "Requirement already satisfied: gitpython>=3.1.2 in /home/divya/.local/lib/python3.8/site-packages (from fitlog->-r requirements.txt (line 2)) (3.1.31)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers==4.6.1->-r requirements.txt (line 1)) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers==4.6.1->-r requirements.txt (line 1)) (2019.11.28)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/divya/.local/lib/python3.8/site-packages (from requests->transformers==4.6.1->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers==4.6.1->-r requirements.txt (line 1)) (2.8)\n",
            "Requirement already satisfied: click in /home/divya/.local/lib/python3.8/site-packages (from sacremoses->transformers==4.6.1->-r requirements.txt (line 1)) (8.1.3)\n",
            "Requirement already satisfied: joblib in /home/divya/.local/lib/python3.8/site-packages (from sacremoses->transformers==4.6.1->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->transformers==4.6.1->-r requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /home/divya/.local/lib/python3.8/site-packages (from flask>=1.0.2->fitlog->-r requirements.txt (line 2)) (1.6.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0; python_version < \"3.10\" in /home/divya/.local/lib/python3.8/site-packages (from flask>=1.0.2->fitlog->-r requirements.txt (line 2)) (6.6.0)\n",
            "Requirement already satisfied: Werkzeug>=2.3.3 in /home/divya/.local/lib/python3.8/site-packages (from flask>=1.0.2->fitlog->-r requirements.txt (line 2)) (2.3.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /home/divya/.local/lib/python3.8/site-packages (from flask>=1.0.2->fitlog->-r requirements.txt (line 2)) (2.1.2)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /home/divya/.local/lib/python3.8/site-packages (from flask>=1.0.2->fitlog->-r requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/divya/.local/lib/python3.8/site-packages (from gitpython>=3.1.2->fitlog->-r requirements.txt (line 2)) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/divya/.local/lib/python3.8/site-packages (from importlib-metadata>=3.6.0; python_version < \"3.10\"->flask>=1.0.2->fitlog->-r requirements.txt (line 2)) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/divya/.local/lib/python3.8/site-packages (from Werkzeug>=2.3.3->flask>=1.0.2->fitlog->-r requirements.txt (line 2)) (2.1.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /home/divya/.local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.2->fitlog->-r requirements.txt (line 2)) (5.0.0)\n"
          ]
        }
      ],
      "source": [
        "# The code closely follows the original ElasticBERT repository\n",
        "# Feature to train models with a given exit configuration is added\n",
        "# !git clone https://github.com/MLiONS/MutiExitDNNs.git\n",
        "\n",
        "\n",
        "%cd path../ElasticBERT\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "A26ZgAoxPyiJ"
      },
      "outputs": [],
      "source": [
        "#All the hyper-parameters/ location to training dataset are set in\n",
        "#MultiExitDNNs -> finetune-dynamic -> finetune_elue_entropy.sh file\n",
        "\n",
        "#1)Set the correct location to SST-2 dataset\n",
        "#All models are trained on SST-2 \"train\" split and evaluated on \"dev\" split\n",
        "#\"train.tsv\" and \"dev.tsv\" are expected to be in ELUE_DIR/TASK_NAME\n",
        "#You can set both ELUE_DIR and TASK_NAME in finetune_elue_entropy.sh\n",
        "#Or change the dataset directory using \"data_dir\" option\n",
        "\n",
        "#2)Please change the \"num_output_layers\" option as per the desired exit-configuration\n",
        "\n",
        "#3)Model checkpoints will be saved at \"output_dir\" and\n",
        "#logs will be available at \"log_dir\"\n",
        "# !bash path../ElasticBERT/finetune-dynamic/finetune_elue_entropy.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tfcWxU28kkl"
      },
      "source": [
        "# Part-1 : Section B\n",
        "Generating the prediction matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "acoXLlG2y1ty"
      },
      "outputs": [],
      "source": [
        "#Evaluation on other datasets-IMDb or Yelp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb9mBUI5y1q-",
        "outputId": "f06bf2bb-9a73-407f-b80d-8b5064d1cc1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/divya/divyaJyoti/UBERT/MutiExitDNNs/ElasticBERT/finetune-dynamic\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer as ElasticBertTokenizer\n",
        "\n",
        "#Set the current directory location inside \"finetune-dynamic\" folder\n",
        "%cd path../ElasticBERT/finetune-dynamic\n",
        "\n",
        "from models.configuration_elasticbert import ElasticBertConfig\n",
        "from models.modeling_elasticbert_entropy import ElasticBertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "ZkT2IrL2b90d"
      },
      "outputs": [],
      "source": [
        "#Set location to the best performing model\n",
        "#Model checkpoints are saved at \"output_dir\" from Part-1: Section A\n",
        "checkpoint_sst = 'path../ElasticBERT/finetune-dynamic/ckpts/elue/entropy/SST-2/checkpoint-1335'\n",
        "checkpoint_mrpc = 'path../ElasticBERT/finetune-dynamic/ckpts/elue/entropy/MRPC/checkpoint-575'\n",
        "checkpoint_rte = 'path../ElasticBERT/finetune-dynamic/ckpts/elue/entropy/RTE/checkpoint-390'\n",
        "checkpoint_mnli = 'path../ElasticBERT/finetune-dynamic/ckpts/elue/entropy/MNLI/checkpoint-61360'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "cCv-3N0CaM0s"
      },
      "outputs": [],
      "source": [
        "data_checkpoint={'imdb':checkpoint_sst,'yelp':checkpoint_sst,'qqp':checkpoint_mrpc,'scitail':checkpoint_rte,'snli':checkpoint_mnli}\n",
        "#model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "AFt7llc_g130"
      },
      "outputs": [],
      "source": [
        "def get_args(arg_vec):\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # Required parameters\n",
        "    parser.add_argument(\n",
        "        \"--num_hidden_layers\",\n",
        "        default=None,\n",
        "        type=int,\n",
        "        required=True,\n",
        "        help='The number of layers to import.',\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--num_output_layers\",\n",
        "        nargs = 12,\n",
        "        default=None,\n",
        "        type=int,\n",
        "        required=True,\n",
        "        help='The number of layers to output.',\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--data_dir\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model_name_or_path\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"Path to pre-trained model or shortcut name.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--task_name\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"The name of the task to train selected in the list.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output_dir\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--log_dir\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"The output directory where the logs will be written.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--spec_eval\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=False,\n",
        "        help=\"'Set as train or test based on specific split on which to evaluate'\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--patience\",\n",
        "        default='0',\n",
        "        type=str,\n",
        "        required=False,\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--regression_threshold\",\n",
        "        default=0,\n",
        "        type=float,\n",
        "        required=False,\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--early_exit_entropy\",\n",
        "        default='0.1',\n",
        "        type=str,\n",
        "        required=False,\n",
        "    )\n",
        "    # Other parameters\n",
        "    parser.add_argument(\n",
        "        \"--load\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        help=\"The path of ckpts used to continue training.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--config_name\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Pretrained config name or path if not the same as model_name\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--tokenizer_name\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--cache_dir\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Where do you want to store the pre-trained models downloaded from huggingface.co\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_seq_length\",\n",
        "        default=128,\n",
        "        type=int,\n",
        "        help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "             \"than this will be truncated, sequences shorter will be padded.\",\n",
        "    )\n",
        "    parser.add_argument(\"--debug\", action=\"store_true\", help=\"Whether to use debug mode.\")\n",
        "    parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n",
        "    parser.add_argument(\"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the dev set.\")\n",
        "    parser.add_argument(\n",
        "        \"--evaluate_during_training\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Run evaluation during training at each logging step.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--do_lower_case\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Set this flag if you are using an uncased model.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--per_gpu_train_batch_size\",\n",
        "        default=8,\n",
        "        type=int,\n",
        "        help=\"Batch size per GPU/CPU for training.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--per_gpu_eval_batch_size\",\n",
        "        default=1,\n",
        "        type=int,\n",
        "        help=\"Batch size per GPU/CPU for evaluation.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--gradient_accumulation_steps\",\n",
        "        type=int,\n",
        "        default=1,\n",
        "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--learning_rate\",\n",
        "        default=5e-5,\n",
        "        type=float,\n",
        "        help=\"The initial learning rate for Adam.\",\n",
        "    )\n",
        "    parser.add_argument(\"--weight_decay\", default=0.01, type=float, help=\"Weight decay if we apply some.\")\n",
        "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
        "    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
        "    parser.add_argument(\n",
        "        \"--num_train_epochs\",\n",
        "        default=3.0,\n",
        "        type=float,\n",
        "        help=\"Total number of training epochs to perform.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_steps\",\n",
        "        default=-1,\n",
        "        type=int,\n",
        "        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
        "    )\n",
        "    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
        "    parser.add_argument(\"--warmup_rate\", default=0, type=float, help=\"Linear warmup over warmup_rate.\")\n",
        "\n",
        "    parser.add_argument(\"--logging_steps\", type=int, default=500, help=\"Log every X updates steps.\")\n",
        "    parser.add_argument(\n",
        "        \"--save_steps\",\n",
        "        type=int,\n",
        "        default=500,\n",
        "        help=\"Save checkpoint every X updates steps.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--eval_all_checkpoints\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n",
        "    )\n",
        "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
        "    parser.add_argument(\n",
        "        \"--overwrite_output_dir\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Overwrite the content of the output directory\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--overwrite_cache\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Overwrite the cached training and evaluation sets\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--not_save_model\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Do not save model checkpoints\"\n",
        "    )\n",
        "    parser.add_argument(\"--seed\", type=int, default=6, help=\"random seed for initialization\")\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--fp16\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--fp16_opt_level\",\n",
        "        type=str,\n",
        "        default=\"O1\",\n",
        "        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
        "             \"See details at https://nvidia.github.io/apex/amp.html\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--local_rank\",\n",
        "        type=int,\n",
        "        default=-1,\n",
        "        help=\"For distributed training: local_rank\",\n",
        "    )\n",
        "    parser.add_argument(\"--server_ip\", type=str, default=\"\", help=\"For distant debugging.\")\n",
        "    parser.add_argument(\"--server_port\", type=str, default=\"\", help=\"For distant debugging.\")\n",
        "    args = parser.parse_args(arg_vec)\n",
        "\n",
        "    return args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "E2cX_ym5pJwl"
      },
      "outputs": [],
      "source": [
        "from load_data import (\n",
        "    load_and_cache_examples_glue,\n",
        "    load_and_cache_examples_elue,\n",
        ")\n",
        "\n",
        "def evaluate_elue_entropy(args, model, tokenizer, prefix=\"\", eval_highway=False, entropy=0.):\n",
        "    model.elasticbert.set_early_exit_entropy(entropy)\n",
        "    model.elasticbert.set_eval_state(eval_highway)\n",
        "    model.elasticbert.reset_stats()\n",
        "\n",
        "    eval_task = args.task_name.lower()\n",
        "    eval_output_dir = args.output_dir\n",
        "\n",
        "    num_op_layers = args.num_output_layers\n",
        "\n",
        "    results = {}\n",
        "    results_all = []\n",
        "    exit_layer = []\n",
        "    for i in range(sum(num_op_layers)):\n",
        "        results_all.append({})\n",
        "\n",
        "    if args.task_name in ('imdb','yelp','scitail','snli'):\n",
        "      if args.spec_eval:\n",
        "          eval_dataset = load_and_cache_examples_elue(args, eval_task, tokenizer, data_type=args.spec_eval)\n",
        "      else:\n",
        "          eval_dataset = load_and_cache_examples_elue(args, eval_task, tokenizer, data_type='train')\n",
        "    else:\n",
        "      if args.spec_eval:\n",
        "        eval_dataset = load_and_cache_examples_glue(args, eval_task, tokenizer, data_type=args.spec_eval)\n",
        "      else:\n",
        "        eval_dataset = load_and_cache_examples_glue(args, eval_task, tokenizer, data_type='train')\n",
        "\n",
        "    if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
        "        os.makedirs(eval_output_dir)\n",
        "\n",
        "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
        "    # Note that DistributedSampler samples randomly\n",
        "    eval_sampler = SequentialSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
        "\n",
        "    # multi-gpu eval\n",
        "    if args.n_gpu > 1 and not isinstance(model, torch.nn.DataParallel):\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Eval!\n",
        "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    preds = None\n",
        "    preds_all = []\n",
        "    pred_tuple = []\n",
        "    for i in range(sum(num_op_layers)):\n",
        "        preds_all.append(None)\n",
        "        pred_tuple.append(None)\n",
        "    out_label_ids = None\n",
        "\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(args.device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[0],\n",
        "                \"attention_mask\": batch[1],\n",
        "                \"labels\": batch[-1],\n",
        "            }\n",
        "            inputs[\"token_type_ids\"] = batch[2]\n",
        "            outputs = model(**inputs)\n",
        "            tmp_eval_loss, logits = outputs[:2]\n",
        "\n",
        "            eval_loss += tmp_eval_loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "        if out_label_ids is None:\n",
        "            out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
        "        else:\n",
        "            out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
        "        if not eval_highway:\n",
        "            for i, pred in enumerate(preds_all):\n",
        "                if pred is None:\n",
        "                    preds_all[i] = logits[i].detach().cpu().numpy()\n",
        "                else:\n",
        "                    preds_all[i] = np.append(pred, logits[i].detach().cpu().numpy(), axis=0)\n",
        "        else:\n",
        "            if preds is None:\n",
        "                preds = logits.detach().cpu().numpy()\n",
        "            else:\n",
        "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    if args.output_mode == \"classification\":\n",
        "        if not eval_highway:\n",
        "            for i, pred in enumerate(preds_all):\n",
        "                preds_all[i] = np.argmax(pred, axis = 1)\n",
        "                pred_tuple[i] = pred\n",
        "        else:\n",
        "            preds = np.argmax(preds, axis = 1)\n",
        "            pred_tuple[i] = pred\n",
        "\n",
        "    elif args.output_mode == \"regression\":\n",
        "        if not eval_highway:\n",
        "            for i, pred in enumerate(preds_all):\n",
        "                preds_all[i] = np.squeeze(pred)\n",
        "        else:\n",
        "            preds = np.squeeze(preds)\n",
        "\n",
        "    if not eval_highway:\n",
        "        for i, pred in enumerate(preds_all):\n",
        "            if eval_task == 'rte' or 'qnli' or 'wnli' or 'qqp':\n",
        "                eval_task = 'scitail'\n",
        "            if eval_task == 'mnli':\n",
        "                eval_task = 'snli'\n",
        "            if eval_task == 'yelp':\n",
        "              eval_task = 'imdb'\n",
        "            result = elue_compute_metrics(eval_task, pred, out_label_ids)\n",
        "            results_all[i].update(result)\n",
        "\n",
        "    else:\n",
        "        if eval_task == 'rte' or 'qnli' or 'wnli' or 'qqp':\n",
        "                eval_task = 'scitail'\n",
        "        if eval_task == 'mnli':\n",
        "                eval_task = 'snli'\n",
        "        result = elue_compute_metrics(eval_task, preds, out_label_ids)\n",
        "        results.update(result)\n",
        "\n",
        "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "        for key in sorted(result.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "            print(\"  %s = %s\" % (key, str(result[key])))\n",
        "\n",
        "        exiting_layer_every_ins = model.elasticbert.exiting_layer_every_ins\n",
        "        exit_layer.append(exiting_layer_every_ins)\n",
        "\n",
        "    if eval_highway:\n",
        "        speed_up = model.elasticbert.log_stats()\n",
        "        return results, speed_up, exit_layer\n",
        "\n",
        "    if args.spec_eval:\n",
        "      return results_all, preds_all, pred_tuple, out_label_ids\n",
        "\n",
        "    return results_all, preds_all, pred_tuple , out_label_ids\n",
        "    #return results_all, preds_all, out_label_ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "50EjaE5MhPkU"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/hsm207/imdb_data.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "lfKacfaChWSJ"
      },
      "outputs": [],
      "source": [
        "# %cd imdb_data\n",
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "YsgrccgxiiQq"
      },
      "outputs": [],
      "source": [
        "# !tf_upgrade_v2 --infile create_imdb_dataset.py --outfile bar.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "vbLkqld8ipqI"
      },
      "outputs": [],
      "source": [
        "# !python bar.py --output_dir path../UBERT/elue_data/imdb_data/imdb_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "ZyrFjs52hwRW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def get_preds(eval_dataset='snli', data_split='train'):\n",
        "  if eval_dataset in ('imdb','yelp'):\n",
        "    args.spec_eval = 'train'\n",
        "  else:\n",
        "    args.spec_eval = False\n",
        "  args.task_name=eval_dataset.lower()\n",
        "  args.data_dir=ELUE_DIR + '/'+args.task_name\n",
        "\n",
        "  results_all, exit_preds, pred_tuple, op_labels = evaluate_elue_entropy(args, model, tokenizer)\n",
        "\n",
        "\n",
        "  # exit_preds_list = np.stack(exit_preds, axis=1)\n",
        "  # df = pd.DataFrame((exit_preds_list) )\n",
        "  # df['op_labels'] = op_labels\n",
        "\n",
        "  return  results_all, exit_preds, pred_tuple, op_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "V--GIZs_onmG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import scipy\n",
        "def softmax(x):\n",
        "    return(np.exp(x)/np.exp(x).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "hvMGy_hFtTJk"
      },
      "outputs": [],
      "source": [
        "result_dict={}\n",
        "replace_dict={'scitail':{0:1,1:0},'snli':{0:1,1:2,2:0}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxJkyv_xHy-H",
        "outputId": "e676791a-51ed-49db-a84a-6e2a00c290e7"
      },
      "outputs": [],
      "source": [
        "def data_generate(df_list):\n",
        "  for dataset in df_list:\n",
        "    config = ElasticBertConfig.from_pretrained(data_checkpoint[dataset])\n",
        "    tokenizer = ElasticBertTokenizer.from_pretrained(data_checkpoint[dataset])\n",
        "    model = ElasticBertForSequenceClassification.from_pretrained(data_checkpoint[dataset]) \n",
        "    ELUE_DIR='path../UBERT/elue_data'\n",
        "    TASK_NAME=dataset\n",
        "\n",
        "    arg_vec= ['--model_name_or_path', 'fnlp/elasticbert-base',\n",
        "      '--task_name', dataset, \\\n",
        "      '--do_train', \\\n",
        "      '--do_lower_case', \\\n",
        "      '--data_dir', \"path../UBERT/elue_data\", \\\n",
        "      '--log_dir', 'path../ElasticBERT/logs/elue/entropy/SNLI-BTestCheck', \\\n",
        "      '--output_dir', 'path../ElasticBERT/ckpts/elue/entropy/SNLI-BTestCheck', \\\n",
        "      '--num_hidden_layers', '12', \\\n",
        "      '--num_output_layers', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', \\\n",
        "      '--max_seq_length', '128', \\\n",
        "      '--per_gpu_train_batch_size', '32', \\\n",
        "      '--per_gpu_eval_batch_size',' 32', \\\n",
        "      '--learning_rate', '2e-5', \\\n",
        "      '--weight_decay', '0.1', \\\n",
        "      '--save_steps', '50', \\\n",
        "      '--logging_steps', '50', \\\n",
        "      '--num_train_epochs', '5',  \\\n",
        "      '--warmup_rate', '0.06', \\\n",
        "      '--evaluate_during_training', \\\n",
        "      '--overwrite_output_dir'\n",
        "    ]\n",
        "\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    args = get_args(arg_vec)\n",
        "    import torch\n",
        "    if args.local_rank == -1 or args.no_cuda:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
        "        args.n_gpu = torch.cuda.device_count()\n",
        "    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
        "        torch.cuda.set_device(args.local_rank)\n",
        "        device = torch.device(\"cuda\", args.local_rank)\n",
        "        torch.distributed.init_process_group(backend=\"nccl\")\n",
        "        args.n_gpu = torch.cuda.device_count()\n",
        "    args.device = device\n",
        "\n",
        "    args.output_mode = 'classification'\n",
        "\n",
        "    print(args.device)\n",
        "    model.to(args.device)\n",
        "    from elue import elue_compute_metrics\n",
        "    import logging\n",
        "    logger = logging.getLogger(__name__)\n",
        "    from torch.utils.data import DataLoader, SequentialSampler\n",
        "    from torch.utils.data.distributed import DistributedSampler\n",
        "    import os\n",
        "    from tqdm import tqdm\n",
        "    results, final_preds, pred_tuple, op_labels = get_preds(eval_dataset=dataset, data_split='train')\n",
        "    pred_prob_layer=[]\n",
        "    for j in range(len(pred_tuple)):\n",
        "        pred_prob=[]\n",
        "        for i in range(len(pred_tuple[0])):\n",
        "            pred_prob.append((softmax(pred_tuple[j][i])))\n",
        "        pred_prob_layer.append(pred_prob)\n",
        "    prob_df=pd.DataFrame(pred_prob_layer)\n",
        "    prob_df=prob_df.transpose()\n",
        "    prob_df.columns=[f\"tup_layer{i}\" for i in range(1,13)]\n",
        "    prob_df['output_labels']=op_labels\n",
        "    if dataset in replace_dict.keys():\n",
        "      prob_df['output_labels']=prob_df['output_labels'].replace(replace_dict[dataset])\n",
        "    result_dict[dataset]=prob_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_generate(['scitail'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "comment out for find confidence dataset\n",
        "dataset_name=['imdb','scitail','yelp','qqp','snli']\n",
        "data_generate(dataset_name)\n",
        "import pickle\n",
        "with open(\"path../Dataset/confidence_label_dict.pkl\",'wb') as file:\n",
        "    pickle.dump(result_dict,file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
